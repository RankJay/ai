{
  "version": 1,
  "hooks": {
    "sessionStart": [
      {
        "command": ".cursor/hooks/inject-context.ps1",
        "timeout": 5
      }
    ],
    "sessionEnd": [],
    "preToolUse": [
      {
        "type": "prompt",
        "prompt": "Before executing this tool, check: Is this a red-light scenario (security, auth, payments, refactoring touching >5 files)? See .ai/ai-guardrails.md 'Stop and Think Triggers' and 'Risk Assessment Matrix' for full guidance. If yes and no validated plan exists in context, return {\"decision\": \"deny\", \"reason\": \"Red-light scenario requires validated plan. Use /plan first.\"}. Otherwise return {\"decision\": \"allow\"}",
        "matcher": "write",
        "timeout": 5
      }
    ],
    "postToolUse": [],
    "postToolUseFailure": [],
    "subagentStart": [],
    "subagentStop": [],
    "beforeShellExecution": [],
    "afterShellExecution": [],
    "beforeMCPExecution": [],
    "afterMCPExecution": [],
    "beforeReadFile": [],
    "afterFileEdit": [
      {
        "command": ".cursor/hooks/post-edit-check.ps1"
      }
    ],
    "beforeSubmitPrompt": [
      {
        "type": "prompt",
        "prompt": "Analyze this prompt. Is it requesting complex code generation (new features, refactoring >5 files, security-sensitive, architectural changes)? See .ai/ai-guardrails.md for triggers and risk matrix. If YES and user has NOT provided project context or referenced a research/plan document, return {\"continue\": false, \"user_message\": \"Complex task detected. Please start with /research or provide your ai-context.md\"}. If simple task or context provided, return {\"continue\": true}.",
        "timeout": 10
      }
    ],
    "preCompact": [],
    "stop": [
      {
        "command": ".cursor/hooks/extract-learnings.ps1",
        "loop_limit": 3
      }
    ],
    "afterAgentResponse": [],
    "afterAgentThought": [],
    "beforeTabFileRead": [],
    "afterTabFileEdit": []
  }
}
